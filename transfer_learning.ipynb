{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "from models import ModelWrapper\n",
    "from utils import get_train_dataset, get_eval_datasets, get_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.0001\n",
    "epochs_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "resnet = resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_dataset = get_train_dataset(transform=preprocess)\n",
    "tmp_val_dataset, test_dataset = get_eval_datasets(transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward data through frozen layers only once to speed up training\n",
    "def get_features_dataset(model, loader, device=None):\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    for x_batch, y_batch in loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "\n",
    "        result = model(x_batch)\n",
    "        features.append(result.detach().cpu())\n",
    "        labels.append(y_batch.cpu())\n",
    "\n",
    "    features_tensor = torch.cat(features)\n",
    "    labels_tensor = torch.cat(labels)\n",
    "\n",
    "    return torch.utils.data.TensorDataset(features_tensor, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_loader = torch.utils.data.DataLoader(tmp_train_dataset, batch_size=128)\n",
    "tmp_val_loader = torch.utils.data.DataLoader(tmp_val_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_features_dataset(resnet, tmp_train_loader)\n",
    "torch.save(train_dataset.tensors, 'transfer_learning_preprocessed_train.pth')\n",
    "\n",
    "val_dataset = get_features_dataset(resnet, tmp_val_loader)\n",
    "torch.save(val_dataset.tensors, 'transfer_learning_preprocessed_val.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "targets = get_targets(train_dataset)\n",
    "_, counts = targets.unique(return_counts=True)\n",
    "\n",
    "weights = 1 / counts.float()\n",
    "sample_weights = weights[targets.long()]\n",
    "\n",
    "sampler = torch.utils.data.WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True,\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = nn.Sequential(\n",
    "    nn.Dropout(p=0.6),\n",
    "    nn.Linear(512, 43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classificator.parameters(), lr=lr)\n",
    "\n",
    "mw = ModelWrapper(classificator, criterion, optimizer)\n",
    "mw.set_dataloaders(train_loader, val_loader)\n",
    "# mw.set_writer(writer_filename, writer_subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0    loss: 3.5935698182959306   val_loss: 2.972222857475281\n",
      "epoch: 1    loss: 2.876021574558824   val_loss: 2.4912251615524292\n",
      "epoch: 2    loss: 2.431995736354846   val_loss: 2.18025194644928\n",
      "epoch: 3    loss: 2.134095173133047   val_loss: 1.959123113155365\n",
      "epoch: 4    loss: 1.9156980332004967   val_loss: 1.8026808404922485\n",
      "epoch: 5    loss: 1.7522837414125507   val_loss: 1.6791580390930176\n",
      "epoch: 6    loss: 1.6188222956999638   val_loss: 1.5871337676048278\n",
      "epoch: 7    loss: 1.5187039557826576   val_loss: 1.5060655641555787\n",
      "epoch: 8    loss: 1.4215254709481053   val_loss: 1.4446668457984924\n",
      "epoch: 9    loss: 1.3508826956224214   val_loss: 1.3850774884223938\n",
      "epoch: 10    loss: 1.3001562265688151   val_loss: 1.3477281069755553\n",
      "epoch: 11    loss: 1.2430722439688358   val_loss: 1.3046664905548095\n",
      "epoch: 12    loss: 1.2099242643876509   val_loss: 1.2745911502838134\n",
      "epoch: 13    loss: 1.1546711257199922   val_loss: 1.2430265474319457\n",
      "epoch: 14    loss: 1.1354784406543348   val_loss: 1.211836793422699\n",
      "epoch: 15    loss: 1.0878013244085905   val_loss: 1.187053599357605\n",
      "epoch: 16    loss: 1.0698695663344917   val_loss: 1.1564414811134338\n",
      "epoch: 17    loss: 1.0379963520040922   val_loss: 1.1378156995773316\n",
      "epoch: 18    loss: 1.028580951633636   val_loss: 1.1197344994544982\n",
      "epoch: 19    loss: 1.0076502082450538   val_loss: 1.0997634077072143\n",
      "epoch: 20    loss: 0.9819316692899859   val_loss: 1.0823333072662353\n",
      "epoch: 21    loss: 0.9510385339910333   val_loss: 1.0776004076004029\n",
      "epoch: 22    loss: 0.9522331351298464   val_loss: 1.0516060090065003\n",
      "epoch: 23    loss: 0.9243737134066495   val_loss: 1.042367960214615\n",
      "epoch: 24    loss: 0.9136925117250835   val_loss: 1.0343568766117095\n",
      "epoch: 25    loss: 0.9035814701084885   val_loss: 1.0178759467601777\n",
      "epoch: 26    loss: 0.8907142549610594   val_loss: 1.0099058377742767\n",
      "epoch: 27    loss: 0.888622996624577   val_loss: 1.0038989114761352\n",
      "epoch: 28    loss: 0.8735147723170559   val_loss: 0.9944763064384461\n",
      "epoch: 29    loss: 0.8709238590806295   val_loss: 0.9828871703147888\n",
      "epoch: 30    loss: 0.8593611831299997   val_loss: 0.9776211178302765\n",
      "epoch: 31    loss: 0.8543339154937051   val_loss: 0.9656011581420898\n",
      "epoch: 32    loss: 0.8306142468201486   val_loss: 0.9628082656860352\n",
      "epoch: 33    loss: 0.8367657381952094   val_loss: 0.949282283782959\n",
      "epoch: 34    loss: 0.8314386734551791   val_loss: 0.94702157497406\n",
      "epoch: 35    loss: 0.8383360932888597   val_loss: 0.9378897857666015\n",
      "epoch: 36    loss: 0.8167664953396081   val_loss: 0.9397108018398285\n",
      "epoch: 37    loss: 0.8143635221075213   val_loss: 0.9313173365592956\n",
      "epoch: 38    loss: 0.8026584261342099   val_loss: 0.9234902322292328\n",
      "epoch: 39    loss: 0.8024837813879314   val_loss: 0.9200704038143158\n",
      "epoch: 40    loss: 0.7986521966149362   val_loss: 0.9224818670749664\n",
      "epoch: 41    loss: 0.7810761865816618   val_loss: 0.9138616323471069\n",
      "epoch: 42    loss: 0.7862317935701763   val_loss: 0.9048840343952179\n",
      "epoch: 43    loss: 0.7718791000580674   val_loss: 0.9096780025959015\n",
      "epoch: 44    loss: 0.7779474452351839   val_loss: 0.9029403853416443\n",
      "epoch: 45    loss: 0.7789935911671396   val_loss: 0.9009349799156189\n",
      "epoch: 46    loss: 0.7745387383054888   val_loss: 0.8911505925655365\n",
      "epoch: 47    loss: 0.7734627797843167   val_loss: 0.8898490190505981\n",
      "epoch: 48    loss: 0.7616206413250791   val_loss: 0.8859982144832611\n",
      "epoch: 49    loss: 0.752786716776031   val_loss: 0.8821892249584198\n",
      "epoch: 50    loss: 0.7661461787360707   val_loss: 0.8842861366271972\n",
      "epoch: 51    loss: 0.7503620314826235   val_loss: 0.8785143923759461\n",
      "epoch: 52    loss: 0.7483853078915171   val_loss: 0.8775767731666565\n",
      "epoch: 53    loss: 0.739446530786998   val_loss: 0.874601138830185\n",
      "epoch: 54    loss: 0.7513257242275767   val_loss: 0.8728669667243958\n",
      "epoch: 55    loss: 0.7430236256864082   val_loss: 0.8641983950138092\n",
      "epoch: 56    loss: 0.7327643896689255   val_loss: 0.8655486142635346\n",
      "epoch: 57    loss: 0.7405248823348415   val_loss: 0.8573056793212891\n",
      "epoch: 58    loss: 0.7319655529619974   val_loss: 0.8586611807346344\n",
      "epoch: 59    loss: 0.7430594637633511   val_loss: 0.8575496220588684\n",
      "epoch: 60    loss: 0.7216560649529599   val_loss: 0.8498481321334839\n",
      "epoch: 61    loss: 0.7249375898301886   val_loss: 0.8549040985107422\n",
      "epoch: 62    loss: 0.7362588778066863   val_loss: 0.8503365051746369\n",
      "epoch: 63    loss: 0.7312142540963643   val_loss: 0.846418046951294\n",
      "epoch: 64    loss: 0.7285930676893755   val_loss: 0.8470321846008301\n",
      "epoch: 65    loss: 0.7225673963008314   val_loss: 0.8471928739547729\n",
      "epoch: 66    loss: 0.7166028560348675   val_loss: 0.8389431428909302\n",
      "epoch: 67    loss: 0.6974263047202353   val_loss: 0.8396611702442169\n",
      "epoch: 68    loss: 0.7184625313612834   val_loss: 0.8360861325263977\n",
      "epoch: 69    loss: 0.7114743969657205   val_loss: 0.8384142696857453\n",
      "epoch: 70    loss: 0.7217402289929002   val_loss: 0.8383697593212127\n",
      "epoch: 71    loss: 0.7140779445331062   val_loss: 0.8328037273883819\n",
      "epoch: 72    loss: 0.7043912255307704   val_loss: 0.8319733345508575\n",
      "epoch: 73    loss: 0.7031714328738491   val_loss: 0.8315407860279084\n",
      "epoch: 74    loss: 0.7157567494223562   val_loss: 0.8270741605758667\n",
      "epoch: 75    loss: 0.700388937190389   val_loss: 0.8292711317539215\n",
      "epoch: 76    loss: 0.706759832264704   val_loss: 0.831689795255661\n",
      "epoch: 77    loss: 0.7003180341857472   val_loss: 0.8272455477714539\n",
      "epoch: 78    loss: 0.7023081420140974   val_loss: 0.8212656354904175\n",
      "epoch: 79    loss: 0.6982165683399547   val_loss: 0.8233919501304626\n",
      "epoch: 80    loss: 0.7094027941877191   val_loss: 0.8177610325813294\n",
      "epoch: 81    loss: 0.6977647430303564   val_loss: 0.8207714664936065\n",
      "epoch: 82    loss: 0.704662913198106   val_loss: 0.8210363566875458\n",
      "epoch: 83    loss: 0.7085764322554666   val_loss: 0.8184173882007599\n",
      "epoch: 84    loss: 0.6938235815347097   val_loss: 0.8188154065608978\n",
      "epoch: 85    loss: 0.687890440368196   val_loss: 0.8181875371932983\n",
      "epoch: 86    loss: 0.705799907018123   val_loss: 0.814414074420929\n",
      "epoch: 87    loss: 0.6861728849023153   val_loss: 0.8192127537727356\n",
      "epoch: 88    loss: 0.6833757320374393   val_loss: 0.8129048311710357\n",
      "epoch: 89    loss: 0.6854603448838138   val_loss: 0.8137282347679138\n",
      "epoch: 90    loss: 0.6806695130453155   val_loss: 0.8141033899784088\n",
      "epoch: 91    loss: 0.6887812805518009   val_loss: 0.8122657763957978\n",
      "epoch: 92    loss: 0.6851892310181303   val_loss: 0.8089319956302643\n",
      "epoch: 93    loss: 0.6909835407038054   val_loss: 0.81208465218544\n",
      "epoch: 94    loss: 0.6820142286245903   val_loss: 0.8045830380916595\n",
      "epoch: 95    loss: 0.6753191598579644   val_loss: 0.8001790797710419\n",
      "epoch: 96    loss: 0.676294015640277   val_loss: 0.8043468487262726\n",
      "epoch: 97    loss: 0.6791032971947958   val_loss: 0.8038557136058807\n",
      "epoch: 98    loss: 0.6700837128755579   val_loss: 0.8087344527244568\n",
      "epoch: 99    loss: 0.6862002651086835   val_loss: 0.800163209438324\n"
     ]
    }
   ],
   "source": [
    "mw.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7388756927949327\n"
     ]
    }
   ],
   "source": [
    "resnet.eval()\n",
    "\n",
    "y_true = torch.empty(0)\n",
    "y_hat = torch.empty(0)\n",
    "\n",
    "for x, y in test_loader:\n",
    "    x = x.to(device)\n",
    "    y_true = torch.cat([y_true, y])\n",
    "\n",
    "    preds = torch.argmax(resnet(x), dim=1)\n",
    "    y_hat = torch.cat([y_hat, preds.detach().cpu()])\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('signs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9f4863104813bec057feb2748d66631bed7d132fca04f9320e3ff391f4bce7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
